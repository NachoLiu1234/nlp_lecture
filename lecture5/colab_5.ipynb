{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "khd1Mf3U7xl4",
        "colab_type": "code",
        "outputId": "2db662bb-9f65-47ce-9e53-0ef2fa89a9c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EORnh81dxV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = '/content/drive/My Drive/Colab Notebooks/project_1_checkpoint'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n3JilpUrTIYZ",
        "outputId": "a26d0508-f6d8-43fd-8905-8f20cb9d7338",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "! wget http://model.scir.yunfutech.com/model/ltp_data_v3.4.0.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-10 04:06:14--  http://model.scir.yunfutech.com/model/ltp_data_v3.4.0.zip\n",
            "Resolving model.scir.yunfutech.com (model.scir.yunfutech.com)... 47.89.64.233, 47.89.64.202, 47.89.64.204\n",
            "Connecting to model.scir.yunfutech.com (model.scir.yunfutech.com)|47.89.64.233|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 637993278 (608M) [application/zip]\n",
            "Saving to: ‘ltp_data_v3.4.0.zip’\n",
            "\n",
            "ltp_data_v3.4.0.zip 100%[===================>] 608.44M  97.8MB/s    in 7.2s    \n",
            "\n",
            "2020-06-10 04:06:23 (84.4 MB/s) - ‘ltp_data_v3.4.0.zip’ saved [637993278/637993278]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FHo4AlAaTLoH",
        "outputId": "1e6ced85-c3c8-4bb1-9103-125c3430066c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!unzip ltp_data_v3.4.0.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ltp_data_v3.4.0.zip\n",
            "   creating: ltp_data_v3.4.0/\n",
            "  inflating: ltp_data_v3.4.0/cws.model  \n",
            "  inflating: ltp_data_v3.4.0/md5.txt  \n",
            "  inflating: ltp_data_v3.4.0/ner.model  \n",
            "  inflating: ltp_data_v3.4.0/parser.model  \n",
            "  inflating: ltp_data_v3.4.0/pisrl.model  \n",
            "  inflating: ltp_data_v3.4.0/pos.model  \n",
            "  inflating: ltp_data_v3.4.0/version  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YPwFV0vdac8_",
        "outputId": "ebd64baf-dcec-45be-dc11-c075221f6c1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!pip install pyltp"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyltp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/72/2d88c54618cf4d8916832950374a6f265e12289fa9870aeb340800a28a62/pyltp-0.2.1.tar.gz (5.3MB)\n",
            "\u001b[K     |████████████████████████████████| 5.3MB 2.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyltp\n",
            "  Building wheel for pyltp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyltp: filename=pyltp-0.2.1-cp36-cp36m-linux_x86_64.whl size=32004771 sha256=d755c7b7cb4c7dc985be962b75f2e25f0eddf20598011e7cb716f10b715fe721\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/3a/35/b11293efb2c77c0e7b6fa574271d51cddd9abd1f634535343c\n",
            "Successfully built pyltp\n",
            "Installing collected packages: pyltp\n",
            "Successfully installed pyltp-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XQPsZZ4zaKuv",
        "outputId": "80ff73c6-fc00-4161-cf69-dc625da8dc1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!tar -zxvf AutoMaster_TrainSet.tgz"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "._AutoMaster_TrainSet.csv\n",
            "AutoMaster_TrainSet.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4CbF1PubS2n9",
        "outputId": "834b9c5b-584e-487f-cc41-604c1954e21a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from pyltp import SentenceSplitter,NamedEntityRecognizer,Postagger,Parser,Segmentor\n",
        "import pandas as pd\n",
        "from gensim.models.word2vec import LineSentence, Word2Vec\n",
        "import time, shutil, os\n",
        "print(tf.__version__)\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "# shutil.rmtree('checkpoint')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr6C4-h37I97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    calculate encoded output and hidden state from encoder input and initialized encoder hidden\n",
        "    batch by batch and paragraph by paragraph\n",
        "    input is [batch_sz,max_len_x] encoder hidden is [batch_sz, enc_units]\n",
        "    output is [batch_sz, max_len_x, enc_units]\n",
        "    \"\"\"\n",
        "    def __init__(self, enc_units, batch_sz, embedding_matrix):\n",
        "        super(Encoder, self).__init__()\n",
        "        vocab_size, embedding_dim = embedding_matrix.shape[0], embedding_matrix.shape[1]\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units // 2\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], trainable=False)\n",
        "        self.gru = tf.keras.layers.GRU(self.enc_units, return_sequences=True, return_state=True,\n",
        "                                       recurrent_initializer='glorot_uniform')\n",
        "        self.bidirectional_gru = tf.keras.layers.Bidirectional(self.gru)\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "        # [batch_sz,max_train_x,embedding_dim]\n",
        "        x = self.embedding(x)\n",
        "        # output is [batch_sz, max_train_x, enc_units] enc_hidden after concat is [batch_sz, enc_units]\n",
        "        output, forward_state, backward_state = self.bidirectional_gru(x, initial_state=[hidden, hidden])\n",
        "        enc_hidden = tf.keras.layers.concatenate([forward_state, backward_state],axis=-1)\n",
        "        return output, enc_hidden\n",
        "\n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))\n",
        "\n",
        "\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    calculate attention and coverage from dec_hidden enc_output and prev_coverage\n",
        "    one dec_hidden(word) by one dec_hidden\n",
        "    dec_hidden or query is [batch_sz, enc_unit], enc_output or values is [batch_sz, max_train_x, enc_units],\n",
        "    prev_coverage is [batch_sz, max_len_x, 1]\n",
        "    dec_hidden is initialized as enc_hidden, prev_coverage is initialized as None\n",
        "    output context_vector [batch_sz, enc_units] attention_weights & coverage [batch_sz, max_len_x, 1]\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W_h = tf.keras.layers.Dense(units)\n",
        "        self.W_s = tf.keras.layers.Dense(units)\n",
        "        self.W_c = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, dec_hidden, enc_output, enc_pad_mask, use_coverage, prev_coverage):\n",
        "\n",
        "        # prev_coverage [batch_sz, max_len_x, 1]\n",
        "        # 11.07 add enc_pad_mask [batch_sz, max_len_x] to mask attention\n",
        "        # query or dec_hidden [batch_sz, enc_units], values or enc_output [batch_sz, max_len, enc_units]\n",
        "        # hidden_with_time_axis [batch_size, 1, enc_units]\n",
        "        hidden_with_time_axis = tf.expand_dims(dec_hidden, 1)\n",
        "\n",
        "        if use_coverage and prev_coverage is not None:\n",
        "            # self.W_s(values) [batch_sz, max_len, units] self.W_h(hidden_with_time_axis) [batch_sz, 1, units]\n",
        "            # self.W_c(prev_coverage) [batch_sz, max_len, units]  score [batch_sz, max_len, 1]\n",
        "            score = self.V(tf.nn.tanh(self.W_s(enc_output) + self.W_h(hidden_with_time_axis) + self.W_c(prev_coverage)))\n",
        "            # attention_weights shape (batch_size, max_len, 1)\n",
        "            mask = tf.cast(enc_pad_mask, dtype=score.dtype)\n",
        "            masked_score = tf.squeeze(score, axis=-1) * mask\n",
        "            masked_score = tf.expand_dims(masked_score, axis=2)\n",
        "            attention_weights = tf.nn.softmax(masked_score, axis=1)\n",
        "\n",
        "            coverage = attention_weights + prev_coverage\n",
        "\n",
        "        else:\n",
        "            # self.W1(values) [batch_sz, max_len, units] self.W2(hidden_with_time_axis): [batch_sz, 1, units]\n",
        "            # score [batch_sz, max_len, 1]\n",
        "            score = self.V(tf.nn.tanh(self.W_s(enc_output) + self.W_h(hidden_with_time_axis)))\n",
        "            mask = tf.cast(enc_pad_mask, dtype=score.dtype)\n",
        "            masked_score = tf.squeeze(score, axis=-1) * mask\n",
        "            masked_score = tf.expand_dims(masked_score, axis=2)\n",
        "            attention_weights = tf.nn.softmax(masked_score, axis=1)\n",
        "\n",
        "            if use_coverage:\n",
        "                coverage = attention_weights\n",
        "\n",
        "        # [batch_sz, max_len, enc_units]\n",
        "        context_vector = attention_weights * enc_output\n",
        "        # [batch_sz, enc_units]\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        return context_vector, attention_weights, coverage\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    calculate output before pointer generator network\n",
        "    input dec_inp [batch_sz, 1], hidden [batch_sz, enc_units], context_vector [batch_sz, enc_units]\n",
        "    output dec_inp_context [batch_sz,1,embedding_dim+enc_units] dec_pred [batch_size,vocab_size] dec_hidden [batch_sz,dec_units]\n",
        "    \"\"\"\n",
        "    def __init__(self, dec_units, batch_sz, embedding_matrix):\n",
        "        super(Decoder, self).__init__()\n",
        "        vocab_size, embedding_dim = embedding_matrix.shape[0], embedding_matrix.shape[1]\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], trainable=False)\n",
        "        self.gru = tf.keras.layers.GRU(self.dec_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size, activation=tf.keras.activations.softmax)\n",
        "\n",
        "    def call(self, dec_inp, dec_hidden, context_vector):\n",
        "        # context_vector[batch_sz, enc_units]\n",
        "        # dec_hidden [batch_sz, dec_units] NOTE dec_units == enc_units\n",
        "        # dec_inp shape [batch_size, 1, embedding_dim]\n",
        "        dec_inp = self.embedding(dec_inp)\n",
        "        # dec_inp shape [batch_sz, 1, embedding_dim + enc_units]\n",
        "        dec_inp_context = tf.concat([tf.expand_dims(context_vector, 1), dec_inp], axis=-1)\n",
        "        # output [batch_sz, 1, dec_units] state [batch_sz, dec_units]\n",
        "        output, dec_hidden = self.gru(dec_inp_context)\n",
        "        # output shape [batch_size, dec_units]\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        # print('output deduced by dec_hidden', tf.math.reduce_sum(output-dec_hidden)) they are same!!!\n",
        "        # dec_inp shape [batch_size, vocab_size]\n",
        "        dec_pred = self.fc(output)\n",
        "        return dec_inp_context, dec_pred, dec_hidden\n",
        "\n",
        "\n",
        "class Pointer(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    calculate Pgen\n",
        "    input context_vector [batch_sz,enc_units] dec_hidden [batch_sz,dec_units] dec_inp_context [batch_sz,1,embedding_dim+enc_units]\n",
        "    output scaler pgen\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(Pointer, self).__init__()\n",
        "        self.w_s_reduce = tf.keras.layers.Dense(1)\n",
        "        self.w_i_reduce = tf.keras.layers.Dense(1)\n",
        "        self.w_c_reduce = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, context_vector, dec_hidden, dec_inp):\n",
        "        # change dec_inp_context to [batch_sz,embedding_dim+enc_units]\n",
        "        dec_inp = tf.squeeze(dec_inp, axis=1)\n",
        "        pgen = tf.nn.sigmoid(self.w_s_reduce(dec_hidden) + self.w_c_reduce(context_vector) + self.w_i_reduce(dec_inp))\n",
        "        return pgen\n",
        "\n",
        "class PGN(tf.keras.Model):\n",
        "    \"\"\"\n",
        "    create pgn model\n",
        "    input\n",
        "    output\n",
        "    \"\"\"\n",
        "    def __init__(self, gru_units, att_units, batch_sz, embedding_matrix):\n",
        "        super(PGN, self).__init__()\n",
        "        vocab_size, embedding_dim = embedding_matrix.shape[0], embedding_matrix.shape[1]\n",
        "        self.enc_units = gru_units\n",
        "        self.dec_units = gru_units\n",
        "        self.att_units = att_units\n",
        "        self.encoder = Encoder(self.enc_units, batch_sz, embedding_matrix)\n",
        "        self.attention = BahdanauAttention(self.att_units)\n",
        "        self.decoder = Decoder(self.dec_units, batch_sz, embedding_matrix)\n",
        "        self.pointer = Pointer()\n",
        "\n",
        "    def call_encoder(self, enc_inp):\n",
        "        enc_hidden = self.encoder.initialize_hidden_state()    # [batch_sz, enc_units]\n",
        "        enc_output, enc_hidden = self.encoder(enc_inp, enc_hidden)   # [batch_sz, max_train_x, enc_units], [batch_sz, enc_units]\n",
        "        return enc_output, enc_hidden\n",
        "\n",
        "    # NOTE dec_inp [batch_sz, max_train_y]\n",
        "    def call(self, dec_inp, enc_extended_inp, enc_pad_mask, batch_oov_len, enc_output, dec_hidden,\n",
        "             use_coverage=True, prev_coverage=None, prediction=False):\n",
        "        predictions = []\n",
        "        attentions = []\n",
        "        coverages = []\n",
        "        p_gens = []\n",
        "\n",
        "        # # initiate_hidden and context_vector for pgn\n",
        "        # enc_hidden = self.encoder.initialize_hidden_state()\n",
        "        # enc_output, enc_hidden = self.encoder(enc_inp, enc_hidden)  # same as above\n",
        "        # # initiate coverage to None or whatever was passed in\n",
        "        # dec_hidden = enc_hidden\n",
        "        # # initiate context_vector and coverage_ret\n",
        "\n",
        "        context_vector, attention_weights, coverage_ret = self.attention(dec_hidden,enc_output,enc_pad_mask,use_coverage,prev_coverage)\n",
        "\n",
        "        if prediction:\n",
        "            decode_steps = dec_inp.shape[1]\n",
        "        else:\n",
        "            decode_steps = dec_inp.shape[1] - 1\n",
        "\n",
        "        for t in range(decode_steps):  # 11.11 iterate over time step max_len_y - 1 !!!!\n",
        "\n",
        "            # attentions.append(attention_weights)\n",
        "            # decoder takes dec_inp, dec_hidden, context_vector, dec_inp shape [batch_size, 1]\n",
        "            # dec_hidden [batch_sz, dec_units] NOTE dec_units == enc_units, context_vector[batch_sz, enc_units]\n",
        "            # decoder gives dec_pred [batch_size,vocab_size] dec_hidden [batch_sz,dec_units]\n",
        "            # using teaching force!!!\n",
        "            attentions.append(attention_weights)\n",
        "            coverages.append(coverage_ret)\n",
        "            dec_inp_context, dec_pred, dec_hidden = self.decoder(tf.expand_dims(dec_inp[:, t], 1), dec_hidden, context_vector)\n",
        "            # attention takes dec_hidden, enc_output, use_coverage = True, prev_coverage = None\n",
        "            # attention gives context_vector, attention_weights, coverage\n",
        "            if not prediction:\n",
        "                context_vector, attention_weights, coverage_ret = self.attention(dec_hidden, enc_output,enc_pad_mask,use_coverage,coverage_ret)\n",
        "            # pointer takes context_vector, dec_hidden, dec_inp\n",
        "            pgen = self.pointer(context_vector, dec_hidden, dec_inp_context)\n",
        "            predictions.append(dec_pred)\n",
        "            p_gens.append(pgen)\n",
        "\n",
        "\n",
        "        # enc_extended_input [batch_sz, max_len_x] predictions [max_len_y, batch_sz, vocab_size]\n",
        "        # attentions [max_len_y, batch_sz, max_len_x, 1] p_gens [max_len_y,]\n",
        "        final_dist = self._calc_final_dist(enc_extended_inp, predictions, attentions, p_gens, batch_oov_len)\n",
        "        # change shape of final_dist from [max_len_y, batch_sz, extend_vocab_size]\n",
        "        # to [batch_sz, max_len_y, extend_vocab_size]\n",
        "        #final_dist = tf.transpose(final_dist, [1, 0, 2])\n",
        "\n",
        "        return final_dist, attentions, coverages, dec_hidden, context_vector, p_gens\n",
        "\n",
        "\n",
        "    def _calc_final_dist(self, enc_extended_inp, vocab_dists, attn_dists, p_gens, batch_oov_len):\n",
        "        \"\"\"\n",
        "        Calculate the final distribution, for the pointer-generator model\n",
        "        Args:\n",
        "        vocab_dists, prediction of decoder List length max_dec_steps of (batch_sz, vocab_size) array.\n",
        "                    The words are in the order they appear in the vocabulary file.\n",
        "        attn_dists: The attention distributions. List length max_dec_steps of (batch_size, max_train_x, 1) array.\n",
        "        _enc_batch_extend_vocab, tokenized enc input (batch_sz, max_train_x) with pgn the in-article oov word is\n",
        "        tonkenized with extended index.\n",
        "        Returns:\n",
        "        final_dists: The final distributions. List length max_dec_steps of (batch_size, extended_vocab_size) arrays.\n",
        "        \"\"\"\n",
        "\n",
        "        max_len_y, batch_sz, vocab_size = len(vocab_dists), vocab_dists[0].shape[0], vocab_dists[0].shape[1]\n",
        "        attn_dists = tf.squeeze(attn_dists, axis = -1) # change to max_dec_steps of (batch_size, max_train_x) array\n",
        "        batch_oov_len = tf.reduce_max(batch_oov_len)  # the maximum (over the batch) size of the extended vocabulary\n",
        "\n",
        "        # p_gens = tf.convert_to_tensor(p_gens)\n",
        "        vocab_dists = [p_gen * dist for (p_gen, dist) in zip(p_gens, vocab_dists)]\n",
        "        attn_dists = [(1 - p_gen) * dist for (p_gen, dist) in zip(p_gens, attn_dists)]\n",
        "        # to substitute above code\n",
        "        # def weight_cross(p_gens, vocab_dists):\n",
        "        #     list_like = tf.TensorArray(dtype=tf.float32,size=1,dynamic_size=True,clear_after_read=False)\n",
        "        #     for i in range(len(p_gens)):\n",
        "        #         list_like = list_like.write(i, p_gens[i] * vocab_dists[i])\n",
        "        #     return list_like.stack()\n",
        "        # vocab_dists = weight_cross(p_gens, vocab_dists)\n",
        "        # attn_dists = weight_cross((1-p_gens), attn_dists)\n",
        "\n",
        "        # Concatenate some zeros to each vocabulary dist, to hold the probabilities for in-article OOV words\n",
        "        extended_vocab_size = vocab_size + batch_oov_len\n",
        "        extra_zeros = tf.zeros((batch_sz, batch_oov_len))\n",
        "        vocab_dists_extended = [tf.concat(axis=1, values=[dist, extra_zeros]) for dist in vocab_dists]\n",
        "\n",
        "        # extra_zeros = tf.zeros((max_len_y, batch_sz, batch_oov_len))\n",
        "        # vocab_dists_extended = tf.concat(axis=2, values=[vocab_dists,extra_zeros])\n",
        "        # list length max_dec_steps of shape (batch_size, extended_vsize) [max_len_y, batch_sz, extended_vsize]\n",
        "        #vocab_dists_extended = [tf.concat(axis=1, values=[dist, extra_zeros]) for dist in vocab_dists]\n",
        "        # to substitute above code\n",
        "\n",
        "\n",
        "        # Project the values in the attention distributions onto the appropriate entries in the final distributions\n",
        "        # This means that if a_i = 0.1 and the ith encoder word is w, and w has index 500 in the vocabulary,\n",
        "        # then we add 0.1 onto the 500th entry of the final distribution\n",
        "        # This is done for each decoder timestep.\n",
        "        # This is fiddly; we use tf.scatter_nd to do the projection\n",
        "        batch_nums = tf.range(0, limit=batch_sz)  # shape (batch_size)\n",
        "        batch_nums = tf.expand_dims(batch_nums, 1)  # shape (batch_size, 1)\n",
        "        max_len_x = tf.shape(enc_extended_inp)[1]  # number of states we attend over\n",
        "        batch_nums = tf.tile(batch_nums, [1, max_len_x])  # shape (batch_size, max_train_x)\n",
        "        indices = tf.stack((batch_nums, enc_extended_inp), axis=2)  # shape (batch_size, max_train_x, 2)\n",
        "        shape = (batch_sz, extended_vocab_size)\n",
        "        # list length max_dec_steps (batch_size, extended_vocab_size)\n",
        "        attn_dists_projected = [tf.scatter_nd(indices, copy_dist, shape) for copy_dist in attn_dists]\n",
        "        # substitute above code\n",
        "        # temp = tf.TensorArray(dtype=tf.float32,size=1,dynamic_size=True,clear_after_read=False)\n",
        "        # for i in range(p_gens.shape[0]):  # which equal to max_len_y\n",
        "        #     temp = temp.write(i, tf.scatter_nd(indices, attn_dists[i], shape))\n",
        "        # attn_dists_projected = temp.stack()\n",
        "\n",
        "        # Add the vocab distributions and the copy distributions together to get the final distributions\n",
        "        # final_dists is a list length max_dec_steps; each entry is a tensor shape (batch_size, extended_vsize) giving\n",
        "        # the final distribution for that decoder timestep\n",
        "        # Note that for decoder timesteps and examples corresponding to a [PAD] token, this is junk - ignore.\n",
        "        final_dists = [vocab_dist+copy_dist for (vocab_dist,copy_dist) in zip(vocab_dists_extended,attn_dists_projected)]\n",
        "        # to substitute code above\n",
        "        # final_dists = tf.add(vocab_dists_extended,attn_dists_projected)\n",
        "\n",
        "        return final_dists\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV3_1CCz7I99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_function(real, pred, padding_mask):\n",
        "    #  pred is list of list, max_len_y * [batch_sz, extend_vocabsize] (without argmax) real & mask [batch_sz, max_len_y]\n",
        "    #mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss = 0\n",
        "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(reduction=\"none\")\n",
        "    for t in range(real.shape[1]-1):\n",
        "        loss_ = loss_object(real[:,t+1], pred[t])    # note this change 11.11 [batch_sz,]\n",
        "        mask = tf.cast(padding_mask[:,t+1], dtype=loss_.dtype)\n",
        "        loss_ *= mask\n",
        "        # print('loss_:', loss_)\n",
        "        loss_ = tf.reduce_mean(loss_, axis=0)  # batch-wise\n",
        "        loss += loss_\n",
        "        # print('loss and loss at each time step(batch sum)', loss, loss_)\n",
        "#     tf.print(\"loss:\",loss)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def coverage_loss(attn_dists, coverages, padding_mask):\n",
        "    # attn_dists: [max_len_y, batch_sz, max_len_x, 1]\n",
        "    attn_dists = tf.squeeze(attn_dists, axis=-1)   # [max_len_y, batch_sz, max_len]\n",
        "    coverage = tf.zeros_like(attn_dists[0])  # shape (batch_size, max_len_x). Initial coverage is zero.\n",
        "    covlosses = []  # Coverage loss per decoder timestep. Will be list length max_dec_steps containing shape (batch_size).\n",
        "    padding_mask = tf.stack(padding_mask, 1)   # [max_len_y, batch_sz]\n",
        "    mask = tf.cast(padding_mask, dtype=attn_dists[1].dtype)\n",
        "    for i,a in enumerate(attn_dists):\n",
        "        covloss = tf.reduce_sum(tf.minimum(a, coverage), [1])  # calculate the coverage loss for this step\n",
        "        # update the coverage vector\n",
        "        coverage += a\n",
        "        covloss = covloss * mask[i,:]\n",
        "        covlosses.append(covloss)\n",
        "    loss = tf.reduce_sum(tf.reduce_mean(covlosses, axis=0))\n",
        "#     tf.print('coverage loss(batch sum):', loss)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bGUCcT_HS2oB",
        "colab": {}
      },
      "source": [
        "vocabulary_dimension = 100\n",
        "gru_unites = 128\n",
        "attn_units = 32\n",
        "batch_size = 128\n",
        "learning_rate = 0.001\n",
        "EPOCHS = 150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3xEzXL61S2oE",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('./AutoMaster_TrainSet.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TNweMNQKS2oG",
        "colab": {}
      },
      "source": [
        "cws_model = \"./ltp_data_v3.4.0/cws.model\"\n",
        "\n",
        "def get_word_list(sentence=None,sentences=None,model=cws_model):\n",
        "    #得到分词\n",
        "    segmentor = Segmentor()\n",
        "    segmentor.load(model)\n",
        "    if sentences is not None:\n",
        "        for i, s in enumerate(sentences):\n",
        "            sentences[i] = list(segmentor.segment(s))\n",
        "        return sentences\n",
        "    else:\n",
        "        word_list = list(segmentor.segment(sentence))\n",
        "    segmentor.release()\n",
        "    return word_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lo3WhngzS2oJ",
        "colab": {}
      },
      "source": [
        "inp = list(df.Question)\n",
        "outp = list(df.Report)\n",
        "assert len(inp) == len(outp)\n",
        "\n",
        "# 去除随时联系, 查阅资料等无意义回答\n",
        "drop_index_set = set()\n",
        "for index, (i, o) in enumerate(zip(inp, outp)):\n",
        "    if not type(i) == type(o) == str or len(i) < 8 or len(o) < 8:\n",
        "        drop_index_set.add(index)\n",
        "\n",
        "inp = [el for i, el in enumerate(inp) if i not in drop_index_set]\n",
        "outp = [el for i, el in enumerate(outp) if i not in drop_index_set]\n",
        "\n",
        "inp = get_word_list(sentences=inp)\n",
        "outp = get_word_list(sentences=outp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fxuRgNlNS2oL",
        "colab": {}
      },
      "source": [
        "def get_length(tensor):\n",
        "    length = sorted([len(t) for t in tensor])\n",
        "    return length[int(len(length) * 0.95)] + 2\n",
        "\n",
        "inp_length = get_length(inp)\n",
        "outp_length = get_length(outp)\n",
        "\n",
        "with open('../gensim_input.txt', 'w') as f:\n",
        "    for s in inp:\n",
        "        s = ['<start>'] + s + ['<end>']\n",
        "        f.write(' '.join(s) + '\\n')\n",
        "    for s in outp:\n",
        "        s = ['<start>'] + s + ['<end>']\n",
        "        f.write(' '.join(s) + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tK2OyuSsS2oN",
        "scrolled": true,
        "outputId": "35f18934-d990-4188-92eb-e6c1ab874f9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "! head 10 ../gensim_input.txt"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "head: cannot open '10' for reading: No such file or directory\n",
            "==> ../gensim_input.txt <==\n",
            "<start> 2010 款 宝马 X1 ， 2011年 出厂 ， 2.0 排量 ， 通用 6L45 变速箱 ， 原地 换 挡 位 PRND 车辆 闯动 ， 行驶 升降档 正常 ， 4 轮 离 地 换 挡 无 冲击感 ， 更换 变速箱 油 12L 无 改变 。 试过 一 辆 2014年 进口 X1 原地 换 挡位 也 有 冲击感 ， 这 是 什么 情况 ， 哪里 的 问题 <end>\n",
            "<start> 3.0V6 发动机 号 在 什么 位置 ， 有 照片 最 好 ！ <end>\n",
            "<start> 2012款 奔驰 c180 怎么样 ， 维修 保养 ， 动力 ， 值得 拥有 吗 <end>\n",
            "<start> 科鲁兹 变速箱 旁边 漏 机油 <end>\n",
            "<start> 我 要 怎么 才 能 知道 车子 断开 电瓶 电源 之后 要 不 要 做 节气门 或 防盗 ， 音响 等 的 重置 ， 还有 节气门 重 置 是 不 是 所有 车型 都 一样 ， 打开 电源 不 启动 车子 ， 油门 踩 到底 五 秒 ， 重复 几 次 就 可以 了 。 其他 设备 要 密码 才 行 是 不 是 <end>\n",
            "<start> 昌河 Q35 音响 怎么 拆 装 <end>\n",
            "<start> 长安 35 朝阳 轮胎 不 要 里面 的 钢圈 。 用 我 自己 的 钢圈 多少 钱 外面 换 多少 钱 <end>\n",
            "<start> 吉利 远景 外 球笼 上 那个 大 螺丝 是 顺时针 拧 下来 还是 反 的 <end>\n",
            "<start> 五菱 之 光 6376nf ， 自己 装 了 铁将军 防盗器 ， 五线马达 的 白褐 两 根 信号线 接到 什么 地方 去 ？ 我 想 实现 一 控 三马达 <end>\n",
            "<start> 丰田 花冠 行驶 了 十万 公里 皮带 要 换 吗 <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XRabZtVFS2oQ",
        "outputId": "6445aaa7-a8e3-4736-f55d-cdd69b408614",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "model = Word2Vec(corpus_file='../gensim_input.txt', size=vocabulary_dimension, min_count=10, workers=4, sg=0, negative=5, iter=5)\n",
        "w2v_model = model\n",
        "model.save('/content/drive/My Drive/Colab Notebooks/word2vec.model')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NsMHGNW86ojQ",
        "colab": {}
      },
      "source": [
        "train_x_vocab = []\n",
        "for s in inp:\n",
        "    s = s[:inp_length - 2]\n",
        "    s = ['<start>'] + s + ['<end>']\n",
        "    s = s + ['<pad>'] * (inp_length - len(s))\n",
        "    train_x_vocab.append(s)\n",
        "\n",
        "train_y_vocab = []\n",
        "for s in outp:\n",
        "    s = s[:outp_length - 2]\n",
        "    s = ['<start>'] + s + ['<end>']\n",
        "    s = s + ['<pad>'] * (inp_length - len(s))\n",
        "    train_y_vocab.append(s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ByfsY8DbAYbO",
        "outputId": "efd97d1a-3055-4cf7-9327-523da4ac730d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(model.wv.vocab)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9045"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xkK8OWg26ojS",
        "colab": {}
      },
      "source": [
        "model_vocab_size = len(model.wv.vocab)\n",
        "\n",
        "inp_vocabulary_matrix = np.array([model.wv[model.wv.index2word[i]] for i in range(model_vocab_size)])\n",
        "\n",
        "model.wv['<pad>'] = np.zeros((vocabulary_dimension,))\n",
        "model.wv['<unknown>'] = np.average(inp_vocabulary_matrix, axis=0)\n",
        "\n",
        "pad_wv_index = model.wv.vocab['<pad>'].index\n",
        "unknown_wv_index = model.wv.vocab['<unknown>'].index\n",
        "\n",
        "model_vocab_size = len(model.wv.vocab)\n",
        "inp_vocabulary_matrix = [model.wv[model.wv.index2word[i]] for i in range(model_vocab_size)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7sRxDGVcAt5Y",
        "outputId": "bd5c5469-ad69-460a-fffd-d951457d8be2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.wv.index2word[9046]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<unknown>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "al7duhEL6ojU",
        "colab": {}
      },
      "source": [
        "train_x_token = []\n",
        "train_x_extended_token = []\n",
        "train_x_pad_mask = []\n",
        "train_x_oov_token = []\n",
        "train_x_oov_len = []\n",
        "train_y_token = []\n",
        "train_y_pad_mask = []\n",
        "\n",
        "for s in train_x_vocab:\n",
        "    s_word_index = []\n",
        "    s_oov_index = []\n",
        "    s_oov_dict = {}\n",
        "    pad_mask = [1 for _ in range(len(s))]\n",
        "    for i, w in enumerate(s):\n",
        "        if w == '<unknown>':\n",
        "            raise ValueError\n",
        "        elif w == '<pad>':\n",
        "            pad_mask[i] = 0\n",
        "            s_word_index.append(pad_wv_index)\n",
        "            s_oov_index.append(pad_wv_index)\n",
        "        elif w in model.wv:\n",
        "            s_word_index.append(model.wv.vocab[w].index)\n",
        "            s_oov_index.append(model.wv.vocab[w].index)\n",
        "        else:\n",
        "            s_word_index.append(unknown_wv_index)\n",
        "            if w not in s_oov_dict:\n",
        "                s_oov_dict[w] = len(s_oov_dict)\n",
        "            s_oov_index.append(model_vocab_size + s_oov_dict[w])\n",
        "    \n",
        "    train_x_token.append(s_word_index)\n",
        "    train_x_extended_token.append(s_oov_index)\n",
        "    train_x_pad_mask.append(pad_mask)\n",
        "    train_x_oov_token.append(s_oov_dict)\n",
        "    \n",
        "train_x_oov_token = [list(el.keys()) for el in train_x_oov_token]\n",
        "train_x_oov_len = [len(el) for el in train_x_oov_token]\n",
        "\n",
        "for s in train_y_vocab:\n",
        "    s_word_index = []\n",
        "    pad_mask = [1 for _ in range(len(s))]\n",
        "    for i, w in enumerate(s):\n",
        "        if w == '<unknown>':\n",
        "            raise ValueError\n",
        "        elif w == '<pad>':\n",
        "            pad_mask[i] = 0\n",
        "            s_word_index.append(pad_wv_index)\n",
        "        elif w in model.wv:\n",
        "            s_word_index.append(model.wv.vocab[w].index)\n",
        "        else:\n",
        "            s_word_index.append(unknown_wv_index)\n",
        "    train_y_token.append(s_word_index)\n",
        "    train_y_pad_mask.append(pad_mask)\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UIvoOsWW6ojZ",
        "scrolled": true,
        "outputId": "4ab2183c-b731-47e6-fa66-166072c89ffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "input_train, input_test, extended_input_train, extended_input_test, input_pad_mask_train, input_pad_mask_test, \\\n",
        "    input_oov_train_dict, input_oov_test_dict, input_oov_train_len, input_oov_test_len, output_train, output_test, \\\n",
        "    output_pad_mask_train, output_pad_mask_test = train_test_split(train_x_token, train_x_extended_token, train_x_pad_mask,\n",
        "                                                                   train_x_oov_token, train_x_oov_len,train_y_token,train_y_pad_mask,\n",
        "                                                                   test_size=0.05, random_state=6)\n",
        "train_dataset_len = len(input_train)\n",
        "test_dataset_len = len(input_test)\n",
        "\n",
        "input_train, input_test, extended_input_train, extended_input_test, input_pad_mask_train, input_pad_mask_test, \\\n",
        "input_oov_train_len, input_oov_test_len, output_train, output_test, output_pad_mask_train, output_pad_mask_test = \\\n",
        "tf.convert_to_tensor(input_train), tf.convert_to_tensor(input_test), \\\n",
        "tf.convert_to_tensor(extended_input_train), tf.convert_to_tensor(extended_input_test), \\\n",
        "tf.convert_to_tensor(input_pad_mask_train), tf.convert_to_tensor(input_pad_mask_test), \\\n",
        "tf.convert_to_tensor(input_oov_train_len), tf.convert_to_tensor(input_oov_test_len), \\\n",
        "tf.convert_to_tensor(output_train), tf.convert_to_tensor(output_test), \\\n",
        "tf.convert_to_tensor(output_pad_mask_train), tf.convert_to_tensor(output_pad_mask_test)\n",
        "\n",
        "print('train_test_split, train_input shape:', input_train.shape)\n",
        "print('train_test_split, test_input shape:', input_test.shape)\n",
        "\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices(\n",
        "(input_train, extended_input_train, input_pad_mask_train, input_oov_train_len, output_train, output_pad_mask_train))\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices(\n",
        "(input_test, extended_input_test, input_pad_mask_test, input_oov_test_len, output_test, output_pad_mask_test))\n",
        "dataset_train_batch = dataset_train.batch(batch_size=batch_size, drop_remainder=True)\n",
        "dataset_test_batch = dataset_test.batch(batch_size=batch_size, drop_remainder=True)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_test_split, train_input shape: (74728, 86)\n",
            "train_test_split, test_input shape: (3934, 86)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4bvUWOe7I-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_train_batch, dataset_test_batch, dataset_train_len, dataset_test_len, dataset_train_oov_dict, \\\n",
        "    dataset_test_oov_dict = dataset_train_batch, dataset_test_batch, train_dataset_len, test_dataset_len, \\\n",
        "input_oov_train_dict, input_oov_test_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tTevdKL7I-d",
        "colab_type": "code",
        "outputId": "1436cb64-1fe5-4e6b-9088-b2eb91621612",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset_train_batch"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((128, 86), (128, 86), (128, 86), (128,), (128, 86), (128, 86)), types: (tf.int32, tf.int32, tf.int32, tf.int32, tf.int32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "mDa0BHXi7I-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = PGN(gru_unites, attn_units, batch_size, np.array(inp_vocabulary_matrix))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQm5B6Vd7I-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.002) # , clipvalue=2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOJpaXA17I-i",
        "colab_type": "code",
        "outputId": "01f8c380-3434-4b75-f411-f1e06e124f41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=model.encoder, attention=model.attention,\n",
        "                                 decoder=model.decoder, pointer=model.pointer)\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f5290ba1da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwYv2a8M8qFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, clipvalue=2) # "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN68pZyo7I-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_len = input_train.shape[0]\n",
        "batch_sz = batch_size\n",
        "steps_per_epoch = dataset_len // batch_sz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tbzibRj7I-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_one_batch(mode, w2v_model, model, optimizer, oov_dict, st, inp, targ, enc_extended_inp, enc_pad_mask,\n",
        "                    batch_oov_len, cov_loss_wt, padding_mask=None):\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_hidden = model.call_encoder(inp)\n",
        "        final_dist, attentions, coverages, _, _, _ = model(targ, enc_extended_inp, enc_pad_mask, batch_oov_len,\n",
        "                                                enc_output, enc_hidden, use_coverage=True,prev_coverage=None)\n",
        "        loss = loss_function(targ,final_dist,padding_mask)+cov_loss_wt*coverage_loss(attentions,coverages,padding_mask)\n",
        "        batch_loss = (loss / int(targ.shape[1]))\n",
        "        \n",
        "        variables = model.encoder.trainable_variables + model.attention.trainable_variables + \\\n",
        "                        model.decoder.trainable_variables + model.pointer.trainable_variables\n",
        "        \n",
        "        gradients = tape.gradient(loss, variables)\n",
        "        \n",
        "        optimizer.apply_gradients(zip(gradients, variables))\n",
        "        \n",
        "        return batch_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJOgWzPK7I-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_chkp_epoch = 1\n",
        "train_epoch = EPOCHS\n",
        "cov_loss_wt = 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzCHCmSVGbwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mode, w2v_model, model, optimizer, checkpoint, checkpoint_prefix, save_chkp_epoch,\\\n",
        "dataset_batch, dataset_len, dataset_oov_dict, batch_sz, EPOCHS, cov_loss_wt = 'train', w2v_model, model, \\\n",
        "optimizer, checkpoint, checkpoint_prefix, save_chkp_epoch,\\\n",
        "dataset_train_batch, dataset_train_len, dataset_train_oov_dict, batch_sz, train_epoch, cov_loss_wt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMsiWi_T7I-q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "outputId": "b43c32f2-3287-4a28-aa2b-f0ed4a9505e8"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    total_loss = 0\n",
        "    for (batch, (enc, enc_extend, enc_mask, enc_oov_len, dec, dec_mask)) in enumerate(dataset_train_batch.take(steps_per_epoch)):\n",
        "        st = (batch + 1) * batch_sz\n",
        "        batch_loss = train_one_batch('train',w2v_model,model,optimizer,dataset_oov_dict,st,enc,dec,enc_extend,enc_mask,\n",
        "                                         enc_oov_len, cov_loss_wt=cov_loss_wt, padding_mask=dec_mask)\n",
        "        total_loss += batch_loss\n",
        "        if batch % 500 == 0:\n",
        "                print('$$$$$$$$Epoch {} Batch {} Loss {:.4f}$$$$$$$$'.format(epoch, batch, batch_loss.numpy()))\n",
        "    checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "    learning_rate *= 0.8\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, clipvalue=5)\n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "$$$$$$$$Epoch 0 Batch 0 Loss 2.7963$$$$$$$$\n",
            "$$$$$$$$Epoch 0 Batch 500 Loss 1.2976$$$$$$$$\n",
            "Epoch 1 Loss 1.4467\n",
            "Time taken for 1 epoch 1473.1791985034943 sec\n",
            "\n",
            "$$$$$$$$Epoch 1 Batch 0 Loss 1.3709$$$$$$$$\n",
            "$$$$$$$$Epoch 1 Batch 500 Loss 1.2120$$$$$$$$\n",
            "Epoch 2 Loss 1.2702\n",
            "Time taken for 1 epoch 1476.7114870548248 sec\n",
            "\n",
            "$$$$$$$$Epoch 2 Batch 0 Loss 1.2904$$$$$$$$\n",
            "$$$$$$$$Epoch 2 Batch 500 Loss 1.1646$$$$$$$$\n",
            "Epoch 3 Loss 1.2092\n",
            "Time taken for 1 epoch 1500.4562811851501 sec\n",
            "\n",
            "$$$$$$$$Epoch 3 Batch 0 Loss 1.2472$$$$$$$$\n",
            "$$$$$$$$Epoch 3 Batch 500 Loss 1.1479$$$$$$$$\n",
            "Epoch 4 Loss 1.1859\n",
            "Time taken for 1 epoch 1469.5914680957794 sec\n",
            "\n",
            "$$$$$$$$Epoch 4 Batch 0 Loss 1.2307$$$$$$$$\n",
            "$$$$$$$$Epoch 4 Batch 500 Loss 1.1416$$$$$$$$\n",
            "Epoch 5 Loss 1.1754\n",
            "Time taken for 1 epoch 1466.4474353790283 sec\n",
            "\n",
            "$$$$$$$$Epoch 5 Batch 0 Loss 1.2219$$$$$$$$\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-8b1419cc063e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_sz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         batch_loss = train_one_batch('train',w2v_model,model,optimizer,dataset_oov_dict,st,enc,dec,enc_extend,enc_mask,\n\u001b[0;32m----> 7\u001b[0;31m                                          enc_oov_len, cov_loss_wt=cov_loss_wt, padding_mask=dec_mask)\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-3d33a450d5a0>\u001b[0m in \u001b[0;36mtrain_one_batch\u001b[0;34m(mode, w2v_model, model, optimizer, oov_dict, st, inp, targ, enc_extended_inp, enc_pad_mask, batch_oov_len, cov_loss_wt, padding_mask)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         final_dist, attentions, coverages, _, _, _ = model(targ, enc_extended_inp, enc_pad_mask, batch_oov_len,\n\u001b[0;32m----> 6\u001b[0;31m                                                 enc_output, enc_hidden, use_coverage=True,prev_coverage=None)\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_dist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcov_loss_wt\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcoverage_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcoverages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-90ecfd926a7b>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, dec_inp, enc_extended_inp, enc_pad_mask, batch_oov_len, enc_output, dec_hidden, use_coverage, prev_coverage, prediction)\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;31m# attention gives context_vector, attention_weights, coverage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m                 \u001b[0mcontext_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoverage_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menc_pad_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_coverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcoverage_ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0;31m# pointer takes context_vector, dec_hidden, dec_inp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0mpgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_inp_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-90ecfd926a7b>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, dec_hidden, enc_output, enc_pad_mask, use_coverage, prev_coverage)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mcontext_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m# [batch_sz, enc_units]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mcontext_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcontext_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoverage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mreduce_sum\u001b[0;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m   return reduce_sum_with_dims(input_tensor, axis, keepdims, name,\n\u001b[0;32m-> 1742\u001b[0;31m                               _ReductionDims(input_tensor, axis))\n\u001b[0m\u001b[1;32m   1743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mreduce_sum_with_dims\u001b[0;34m(input_tensor, axis, keepdims, name, dims)\u001b[0m\n\u001b[1;32m   1751\u001b[0m   return _may_reduce_to_scalar(\n\u001b[1;32m   1752\u001b[0m       \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m       gen_math_ops._sum(input_tensor, dims, keepdims, name=name))\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(input, axis, keep_dims, name)\u001b[0m\n\u001b[1;32m  10155\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m  10156\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Sum\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10157\u001b[0;31m         input, axis, \"keep_dims\", keep_dims)\n\u001b[0m\u001b[1;32m  10158\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10159\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdgo7OB2KE25",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "d2a82127-6cc1-4cf3-f2b3-d503cb1cab61"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-b4fc53680272>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Encoder' object has no attribute 'summary'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49dm7KLs9LDb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "0da67421-2829-400a-e75a-af06d0a7b5b7"
      },
      "source": [
        "# predict\n",
        "for (batch, (enc, enc_extend, enc_mask, enc_oov_len, dec, dec_mask)) in enumerate(dataset_test_batch.take(steps_per_epoch)):\n",
        "    batch_loss = test_one_batch('test',w2v_model,model,optimizer,dataset_oov_dict,st,enc,dec,enc_extend,enc_mask,\n",
        "                                         enc_oov_len, cov_loss_wt=cov_loss_wt, padding_mask=dec_mask)\n",
        "    raise"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "85 tf.Tensor(\n",
            "[32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
            " 32 32 32 32 32 32 32 11 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
            " 32 32 32 32 32 32 32 32 32 32 32 11 32 32 32 32 32 32 32 32 32 32 32 32\n",
            " 32 32 32 32 32 32 32 32 32 32 11 32 32 32 32 32 32 32 32 32 11 32 32 32\n",
            " 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
            " 32 32 32 32 32 32 32 32], shape=(128,), dtype=int64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-20f2a69ccd8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     batch_loss = test_one_batch('test',w2v_model,model,optimizer,dataset_oov_dict,st,enc,dec,enc_extend,enc_mask,\n\u001b[1;32m      4\u001b[0m                                          enc_oov_len, cov_loss_wt=cov_loss_wt, padding_mask=dec_mask)\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGbFSkESNlqK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "51ca7561-1504-46eb-b0f8-ac5e622c3280"
      },
      "source": [
        "print(enc_extend)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[   2  196 1517 ... 9045 9045 9045]\n",
            " [   2   15    4 ... 9045 9045 9045]\n",
            " [   2  483  102 ... 9045 9045 9045]\n",
            " ...\n",
            " [   2   32    5 ... 9045 9045 9045]\n",
            " [   2   15    1 ... 9045 9045 9045]\n",
            " [   2  731  744 ... 9045 9045 9045]], shape=(128, 86), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9hoa6e8I2yB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_one_batch(mode, w2v_model, model, optimizer, oov_dict, st, inp, targ, enc_extended_inp, enc_pad_mask,\n",
        "                    batch_oov_len, cov_loss_wt, padding_mask=None):\n",
        "    enc_output, enc_hidden = model.call_encoder(inp)\n",
        "    \n",
        "    final_dist, attentions, coverages, _, _, _ = model(targ, enc_extended_inp, enc_pad_mask, batch_oov_len,\n",
        "                                            enc_output, enc_hidden, use_coverage=True,prev_coverage=None)\n",
        "    \n",
        "    \n",
        "\n",
        "    print(len(final_dist), tf.argmax(final_dist[0], axis=1))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9zpCputMQI7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "f13f8ca9-96fe-4713-d9c3-568cf1c05ce9"
      },
      "source": [
        "len(w2v_model.vocabulary)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-744cbb24c73e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'Word2VecVocab' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbseouEAMwSr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8bfb5d7-ce4b-419e-a156-6c058f350f45"
      },
      "source": [
        "model_vocab_size = len(w2v_model.wv.vocab)\n",
        "model_vocab_size"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9047"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYWs6Ll7M61L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2fa07e22-eedc-4be8-c24b-6b8713ccd5b3"
      },
      "source": [
        "w2v_model.wv.index2word[32]"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'你好'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yujBLL87NSbe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cdeeddf3-8958-46fa-f695-027ed6e286f4"
      },
      "source": [
        "w2v_model.wv.index2word[11]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'检查'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6QnTpfYNT4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}